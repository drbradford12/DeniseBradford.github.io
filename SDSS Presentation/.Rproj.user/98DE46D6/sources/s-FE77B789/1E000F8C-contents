---
title: "Unsupervised Explore Analysis"
bibliography: references.bib
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
#library(sf)
library(cluster)
library(dplyr)
library(ggplot2)
library(readr)
library(Rtsne)
library(tidyr)
library(units)
library(corrplot)
library(here)
library(readxl)
library(factoextra)
library(NbClust)
library(boxr) #This is not working for some reason. Since we have the data using the app locally.
theme_set(theme_bw())

#load("~/Documents/Data-Sources/Data/Combined_IA_data.Rdata")
#load("~/Documents/ShrinkSmartExploration/data/Combined_IA_data.Rdata") #---loading this to understand the methods but need to update the datasets
#source("EDA Data Combine.R")

```

## Outline
- K-means clustering
- Hierarchical Clustering
- Principal component analysis (PCA)

## k - means Clustering Analysis
To Do Check List:
- <input type="checkbox" unchecked> Data Updated?? from the changes in the website on May 2021 </input>
- <input type="checkbox" unchecked> Did I look at the correct variables? </input>
- <input type="checkbox" unchecked> What variables can I add? What variables can I take out? </input>


Things that I should check when completing EDA:
- <input type="checkbox" unchecked> Correlation Matrix </input>
- <input type="checkbox" unchecked> Did you need to scale the data? </input>
- <input type="checkbox" unchecked> What variables are important that are not numeric? </input>


What issues am I having in the analysis for the K-means Analysis?
- <input type="checkbox" unchecked>  </input>

Sourced methodology from https://cedric.cnam.fr/fichiers/art_2579.pdf
```{r}
ia.dist.data.nested <- 
  ia.dist.data.nested %>% 
  remove_rownames %>% 
  column_to_rownames(var="City")

scaled.ia.dist.data <- scale(ia.dist.data.nested[,-7])

#Using the NBClust function to determine the number of clusters that are important to our data

#Using the Euclidean Distance and Complete Method
set.seed(26)
clusterNo = NbClust(scaled.ia.dist.data,distance="euclidean",
min.nc=2,max.nc=10,method="complete",index="all")

#Using the Euclidean Distance and Single Method (This may be the best method for our work, since we want to find the cities that are the most similar)
set.seed(26)
clusterNo = NbClust(scaled.ia.dist.data,distance="euclidean",
min.nc=2,max.nc=10,method="single",index="all")

#Using the Euclidean Distance and Kmeans Method
set.seed(13)
clusterNo = NbClust(scaled.ia.dist.data,distance="euclidean",
min.nc=2,max.nc=10,method="kmeans",index="all")

#Using the Euclidean Distance and Centroid Method
set.seed(78)
clusterNo = NbClust(scaled.ia.dist.data,distance="euclidean",
min.nc=2,max.nc=10,method="centroid",index="all")
```


```{r kmeans}
#Let's look at the distance differences in the hospitals only
scaled.hosp.dist.data <- scale(ia.dist.data.nested[,1]) # Scaling the data by removing the city name and nested data

# View the firt 3 rows of the data
#head(scaled.ia.dist.data, n = 3)

# Compute k-means with k = 4
set.seed(123)
km.res <- kmeans(scaled.ia.dist.data, 2, nstart = 25)
print(km.res)

aggregate(ia.dist.data.nested[,-7], by=list(cluster=km.res$cluster), mean)


#Add the original data to the clustering 
dd <- cbind(ia.dist.data.nested[,-7], cluster = km.res$cluster)
head(dd)

# Cluster number for each of the observations
head(km.res$cluster, 10)

# Cluster size
km.res$size

#Cluster means
km.res$centers

#Visualizing the clusters
fviz_cluster(km.res, ia.dist.data.nested[,-7], ellipse.type = "norm")
```

## Hierarchical clustering
--To do: figure out to handle the NAs in the dataset. Should they be true NAs that are removed from the dataset or should there some sort of restructure in the data

```{r Hierarchical}

# Hierarchical clustering
# ++++++++++++++++++++++++
# Use hcut() which compute hclust and cut the tree
hc.cut <- hcut(scaled.ia.dist.data, k = 3, hc_method = "complete")
# Visualize dendrogram
#fviz_dend(hc.cut, show_labels = FALSE, rect = TRUE)
# Visualize cluster
fviz_cluster(hc.cut, ellipse.type = "convex")


```


## Principal component analysis (PCA)
```{r}
pca_ia_data = ia_data_scaled %>% 
  select(-contains('QOL'))

pca_ia_data = pca_ia_data[,-c(1,2,20,69)] %>% 
  drop_units() %>% 
  mutate(n_post_offices = as.numeric(n_post_offices)) 

M <- cor(pca_ia_data)
corrplot(M, method = "circle")  

irispca <- prcomp(pca_ia_data)
summary(irispca)

```

```{r PAM}
# PAM clustering
# ++++++++++++++++++++
require(cluster)
pam.res <- pam(scaled.ia.dist.data, 3)
 # Visualize pam clustering
fviz_cluster(pam.res, geom = "point", ellipse.type = "norm")

```

